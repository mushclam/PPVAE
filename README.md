# PPVAE
The PyTorch implementation of ACL 2020 paper "[Pre-train and Plug-in: Flexible Conditional Text Generation with Variational Auto-Encoders](https://arxiv.org/abs/1911.03882)".

This is not the official code for the original paper.
Please check the repository [PPVAE](https://github.com/WHUIR/PPVAE/).

This code is not arranged well yet. It will be updated soon.
Please wait.

## Description
### Usage
We envolve the configures to use these code.

We envolve the `launch.json` to run the code with VS code.

### Details
The details for the code will be updated.

### Datasets
We use KorNLUDatasets and KAIST corpus, however we do not upload the datasets.

Code credit: [Yu Duan](mailto:derrick.dy@alibaba-inc.com?cc=xucanwen@whu.edu.cn)

## Citation
If you use the dataset or code in your research, please kindly cite our work:
```bibtex
@inproceedings{duan-etal-2020-pre,
    title = "Pre-train and Plug-in: Flexible Conditional Text Generation with Variational Auto-Encoders",
    author = "Duan, Yu  and
      Xu, Canwen  and
      Pei, Jiaxin  and
      Han, Jialong  and
      Li, Chenliang",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.23",
    pages = "253--262",
}
```
